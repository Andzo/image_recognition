{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import datasets, transforms\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a transform to normalize the data\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])\n",
    "# Download and load the training data\n",
    "trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Download and load the test data\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_size, output_size, hidden_layers, drop_p=0.05):\n",
    "        ''' Builds a feedforward network with arbitrary hidden layers.\n",
    "        \n",
    "            Arguments\n",
    "            ---------\n",
    "            input_size: integer, size of input\n",
    "            output_size: integer, size of output layer\n",
    "            hidden_layers: list of integers, the sizes of the hidden layers\n",
    "            drop_p: float between 0 and 1, dropout probability\n",
    "        '''\n",
    "        \n",
    "        super().__init__()\n",
    "        # Add the first layer, input to a hidden layer\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(input_size, hidden_layers[0])])\n",
    "        \n",
    "        # Add a variable number of more hidden layers\n",
    "        layer_sizes = zip(hidden_layers[:-1], hidden_layers[1:])\n",
    "        self.hidden_layers.extend([nn.Linear(h1, h2) for h1, h2 in layer_sizes])\n",
    "        \n",
    "        self.output = nn.Linear(hidden_layers[-1], output_size)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=drop_p)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        ''' Forward pass through the network, returns the output logits'''\n",
    "        \n",
    "        # Forwardc through each layer in `hidden_layers`, with ReLU activation and dropout\n",
    "        for linear in self.hidden_layers:\n",
    "            x = F.relu(linear(x))\n",
    "            x.dropout = self.dropout(x)\n",
    "        \n",
    "        x = self.output(x)\n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tghe network, define the criterion and optimizer\n",
    "model = Network(input_size=784, output_size=10, hidden_layers=[516, 256])\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The validation function\n",
    "def validation(model, testloader, criterion):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    for images, labels in testloader:\n",
    "        images.resize_(images.shape[0], 784)\n",
    "        output = model.forward(images)\n",
    "        test_loss += criterion(output, labels).item()\n",
    "        ps = torch.exp(output)\n",
    "        equality = (labels.data == ps.max(dim=1)[1])\n",
    "        accuracy += equality.type(torch.FloatTensor).mean()\n",
    "        \n",
    "    return test_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs: 1/2.. Training Loss: 1.1600.. Test Loss: 0.5571.. Test Accuracy: 0.8182\n",
      "Epochs: 1/2.. Training Loss: 0.5355.. Test Loss: 0.4948.. Test Accuracy: 0.8522\n",
      "Epochs: 1/2.. Training Loss: 0.4106.. Test Loss: 0.3801.. Test Accuracy: 0.8800\n",
      "Epochs: 1/2.. Training Loss: 0.3936.. Test Loss: 0.3425.. Test Accuracy: 0.9013\n",
      "Epochs: 1/2.. Training Loss: 0.3342.. Test Loss: 0.3096.. Test Accuracy: 0.9052\n",
      "Epochs: 1/2.. Training Loss: 0.3255.. Test Loss: 0.3038.. Test Accuracy: 0.9069\n",
      "Epochs: 1/2.. Training Loss: 0.3039.. Test Loss: 0.2811.. Test Accuracy: 0.9138\n",
      "Epochs: 1/2.. Training Loss: 0.3291.. Test Loss: 0.3041.. Test Accuracy: 0.8993\n",
      "Epochs: 1/2.. Training Loss: 0.2906.. Test Loss: 0.2412.. Test Accuracy: 0.9258\n",
      "Epochs: 1/2.. Training Loss: 0.2490.. Test Loss: 0.2378.. Test Accuracy: 0.9299\n",
      "Epochs: 1/2.. Training Loss: 0.2268.. Test Loss: 0.2249.. Test Accuracy: 0.9335\n",
      "Epochs: 1/2.. Training Loss: 0.2542.. Test Loss: 0.2292.. Test Accuracy: 0.9280\n",
      "Epochs: 1/2.. Training Loss: 0.2629.. Test Loss: 0.1985.. Test Accuracy: 0.9383\n",
      "Epochs: 1/2.. Training Loss: 0.1956.. Test Loss: 0.1920.. Test Accuracy: 0.9404\n",
      "Epochs: 1/2.. Training Loss: 0.2211.. Test Loss: 0.2227.. Test Accuracy: 0.9319\n",
      "Epochs: 1/2.. Training Loss: 0.2390.. Test Loss: 0.2212.. Test Accuracy: 0.9260\n",
      "Epochs: 1/2.. Training Loss: 0.2097.. Test Loss: 0.1761.. Test Accuracy: 0.9418\n",
      "Epochs: 1/2.. Training Loss: 0.1874.. Test Loss: 0.1849.. Test Accuracy: 0.9411\n",
      "Epochs: 1/2.. Training Loss: 0.1804.. Test Loss: 0.1897.. Test Accuracy: 0.9434\n",
      "Epochs: 1/2.. Training Loss: 0.1669.. Test Loss: 0.1614.. Test Accuracy: 0.9512\n",
      "Epochs: 1/2.. Training Loss: 0.1733.. Test Loss: 0.1644.. Test Accuracy: 0.9483\n",
      "Epochs: 1/2.. Training Loss: 0.1888.. Test Loss: 0.1637.. Test Accuracy: 0.9474\n",
      "Epochs: 1/2.. Training Loss: 0.1705.. Test Loss: 0.1488.. Test Accuracy: 0.9536\n",
      "Epochs: 2/2.. Training Loss: 0.1877.. Test Loss: 0.1670.. Test Accuracy: 0.9471\n",
      "Epochs: 2/2.. Training Loss: 0.1518.. Test Loss: 0.1708.. Test Accuracy: 0.9460\n",
      "Epochs: 2/2.. Training Loss: 0.1536.. Test Loss: 0.1475.. Test Accuracy: 0.9551\n",
      "Epochs: 2/2.. Training Loss: 0.1484.. Test Loss: 0.1745.. Test Accuracy: 0.9436\n",
      "Epochs: 2/2.. Training Loss: 0.1724.. Test Loss: 0.1419.. Test Accuracy: 0.9549\n",
      "Epochs: 2/2.. Training Loss: 0.1425.. Test Loss: 0.1377.. Test Accuracy: 0.9554\n",
      "Epochs: 2/2.. Training Loss: 0.1600.. Test Loss: 0.1438.. Test Accuracy: 0.9565\n",
      "Epochs: 2/2.. Training Loss: 0.1388.. Test Loss: 0.1420.. Test Accuracy: 0.9558\n",
      "Epochs: 2/2.. Training Loss: 0.1164.. Test Loss: 0.1220.. Test Accuracy: 0.9604\n",
      "Epochs: 2/2.. Training Loss: 0.1359.. Test Loss: 0.1371.. Test Accuracy: 0.9561\n",
      "Epochs: 2/2.. Training Loss: 0.1311.. Test Loss: 0.1299.. Test Accuracy: 0.9589\n",
      "Epochs: 2/2.. Training Loss: 0.1369.. Test Loss: 0.1233.. Test Accuracy: 0.9589\n",
      "Epochs: 2/2.. Training Loss: 0.1328.. Test Loss: 0.1410.. Test Accuracy: 0.9554\n",
      "Epochs: 2/2.. Training Loss: 0.1287.. Test Loss: 0.1524.. Test Accuracy: 0.9554\n",
      "Epochs: 2/2.. Training Loss: 0.1412.. Test Loss: 0.1441.. Test Accuracy: 0.9534\n",
      "Epochs: 2/2.. Training Loss: 0.1344.. Test Loss: 0.1241.. Test Accuracy: 0.9613\n",
      "Epochs: 2/2.. Training Loss: 0.1434.. Test Loss: 0.1356.. Test Accuracy: 0.9561\n",
      "Epochs: 2/2.. Training Loss: 0.1433.. Test Loss: 0.1481.. Test Accuracy: 0.9545\n",
      "Epochs: 2/2.. Training Loss: 0.1300.. Test Loss: 0.1644.. Test Accuracy: 0.9472\n",
      "Epochs: 2/2.. Training Loss: 0.1412.. Test Loss: 0.1369.. Test Accuracy: 0.9588\n",
      "Epochs: 2/2.. Training Loss: 0.1174.. Test Loss: 0.1490.. Test Accuracy: 0.9533\n",
      "Epochs: 2/2.. Training Loss: 0.1214.. Test Loss: 0.1048.. Test Accuracy: 0.9668\n",
      "Epochs: 2/2.. Training Loss: 0.0990.. Test Loss: 0.1255.. Test Accuracy: 0.9571\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 40\n",
    "for e in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Flatten images into a 784 long vector\n",
    "        images.resize_(images.size()[0], 784)\n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(images)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        if steps % print_every == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_loss, accuracy = validation(model, testloader, criterion)\n",
    "            print('Epochs: {}/{}..'.format(e+1, epochs),\n",
    "                  'Training Loss: {:.4f}..'.format(running_loss/print_every),\n",
    "                  'Test Loss: {:.4f}..'.format(test_loss/len(testloader)),\n",
    "                  'Test Accuracy: {:.4f}'.format(accuracy/len(testloader)))\n",
    "            running_loss = 0\n",
    "            model.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, ps, version=\"MNIST\"):\n",
    "    ''' Function for viewing an image and it's predicted classes.\n",
    "    '''\n",
    "    ps = ps.data.numpy().squeeze()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)\n",
    "    ax1.imshow(img.resize_(1, 28, 28).numpy().squeeze())\n",
    "    ax1.axis('off')\n",
    "    ax2.barh(np.arange(10), ps)\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(10))\n",
    "    if version == \"MNIST\":\n",
    "        ax2.set_yticklabels(np.arange(10))\n",
    "    elif version == \"Fashion\":\n",
    "        ax2.set_yticklabels(['T-shirt/top',\n",
    "                            'Trouser',\n",
    "                            'Pullover',\n",
    "                            'Dress',\n",
    "                            'Coat',\n",
    "                            'Sandal',\n",
    "                            'Shirt',\n",
    "                            'Sneaker',\n",
    "                            'Bag',\n",
    "                            'Ankle Boot'], size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x648 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "img = images[3]\n",
    "# Convert 2D image to 1D vector\n",
    "img = img.view(1, 784)\n",
    "\n",
    "# Calculate the class probabilities (softmax) for img\n",
    "with torch.no_grad():\n",
    "    output = model.forward(img)\n",
    "\n",
    "ps = torch.exp(output)\n",
    "view_classify(img.view(1, 28, 28), ps, version='MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
